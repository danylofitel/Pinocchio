{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "\n",
    "The goal of this notebook is to explore logistic regression and feature engineering.\n",
    "\n",
    "In this notebook we will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Use Dataframes to do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation\n",
    "\n",
    "We will use a dataset consisting of baby product reviews on Amazon.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"amazon_baby.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Tale of Baby's Days with Peter Rabbit</td>\n",
       "      <td>Lovely book, it's bound tightly so you may not...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>Perfect for new parents. We were able to keep ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>A friend of mine pinned this product on Pinter...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This book is perfect!  I'm a first time new mo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I originally just gave the nanny a pad of pape...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I thought keeping a simple handwritten journal...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nature's Lullabies First Year Sticker Calendar</td>\n",
       "      <td>Space for monthly photos, info and a lot of us...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nature's Lullabies First Year Sticker Calendar</td>\n",
       "      <td>I bought this calender for myself for my secon...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nature's Lullabies First Year Sticker Calendar</td>\n",
       "      <td>I love this little calender, you can keep trac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>This was the only calender I could find for th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I completed a calendar for my son's first year...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I only purchased a second-year calendar for my...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I LOVE this calendar for recording events of m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>Calendar is exactly as described, but I find t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>Wife loves this calender. Comes with a lot of ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Baby's First Journal - Green</td>\n",
       "      <td>Extremely useful! As a new mom, tired and inex...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>My son loves peek a boo at this age of 9 month...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>I like how the book has a hook to attach it to...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>Boppy Noggin NEST Head Support, Denim</td>\n",
       "      <td>This is an expensive pillow that is worth buyi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>Boppy Noggin NEST Head Support, Denim</td>\n",
       "      <td>I first heard about this product when research...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>Boppy Noggin NEST Head Support, Denim</td>\n",
       "      <td>As for some of the other reviews I can underst...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>Boppy Noggin NEST Head Support, Denim</td>\n",
       "      <td>My doctor had told me to do more tummy time wi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>Boppy Noggin NEST Head Support, Denim</td>\n",
       "      <td>This has helped my Now 13 week old son. About ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>Boppy Noggin NEST Head Support, Denim</td>\n",
       "      <td>I'm sure people are buying this product thinki...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>Boppy Noggin NEST Head Support, Denim</td>\n",
       "      <td>My son has partial positional plagio, which is...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>Boppy Noggin NEST Head Support, Denim</td>\n",
       "      <td>The first day I received this I used it. I not...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>Because of the bright colors on this items, i ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>Overall I think this is a good teether - my ba...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>A must have for your baby he will love itthe c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>Our daughter loves this teether.  She is almos...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>My son started showing signs of teething aroun...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>I bought this for my nephew and it keeps him b...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>My son would NOT use any of the teething toys ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>I bought this for my 5 month old great nephew ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>This is not only a teether; its a great toy. I...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>My 4 month old finds this teether's colors ent...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>she likes it because it's long enough for her ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>My 9 month old loves this toy.  It feels good ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>Bought this when my baby was about 5 months ol...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>The shapes this nifty little toy gets into... ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>Such a simple easy toy, but my son loves it.  ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>my girl didnt like this toy at all, it was not...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>My daughter played with it only seldomly as an...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>There no sound or anything and look like there...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>I purchased this for my 6 month old Grandson a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>nice product.  may be too hard for the baby's ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>My 5 mo. old son loves this toy! It's great as...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Munchkin Twisty Figure 8 Teether</td>\n",
       "      <td>Perfect for babies that are teething! very ver...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name  \\\n",
       "0                              Planetwise Flannel Wipes   \n",
       "1                                 Planetwise Wipe Pouch   \n",
       "2                   Annas Dream Full Quilt with 2 Shams   \n",
       "3     Stop Pacifier Sucking without tears with Thumb...   \n",
       "4     Stop Pacifier Sucking without tears with Thumb...   \n",
       "5     Stop Pacifier Sucking without tears with Thumb...   \n",
       "6               A Tale of Baby's Days with Peter Rabbit   \n",
       "7     Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "8     Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "9     Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "10    Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "11    Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "12    Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "13    Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "14       Nature's Lullabies First Year Sticker Calendar   \n",
       "15       Nature's Lullabies First Year Sticker Calendar   \n",
       "16       Nature's Lullabies First Year Sticker Calendar   \n",
       "17      Nature's Lullabies Second Year Sticker Calendar   \n",
       "18      Nature's Lullabies Second Year Sticker Calendar   \n",
       "19      Nature's Lullabies Second Year Sticker Calendar   \n",
       "20      Nature's Lullabies Second Year Sticker Calendar   \n",
       "21      Nature's Lullabies Second Year Sticker Calendar   \n",
       "22      Nature's Lullabies Second Year Sticker Calendar   \n",
       "23      Nature's Lullabies Second Year Sticker Calendar   \n",
       "24      Nature's Lullabies Second Year Sticker Calendar   \n",
       "25      Nature's Lullabies Second Year Sticker Calendar   \n",
       "26                         Baby's First Journal - Green   \n",
       "27                          Lamaze Peekaboo, I Love You   \n",
       "28                          Lamaze Peekaboo, I Love You   \n",
       "29                          Lamaze Peekaboo, I Love You   \n",
       "...                                                 ...   \n",
       "9970              Boppy Noggin NEST Head Support, Denim   \n",
       "9971              Boppy Noggin NEST Head Support, Denim   \n",
       "9972              Boppy Noggin NEST Head Support, Denim   \n",
       "9973              Boppy Noggin NEST Head Support, Denim   \n",
       "9974              Boppy Noggin NEST Head Support, Denim   \n",
       "9975              Boppy Noggin NEST Head Support, Denim   \n",
       "9976              Boppy Noggin NEST Head Support, Denim   \n",
       "9977              Boppy Noggin NEST Head Support, Denim   \n",
       "9978                   Munchkin Twisty Figure 8 Teether   \n",
       "9979                   Munchkin Twisty Figure 8 Teether   \n",
       "9980                   Munchkin Twisty Figure 8 Teether   \n",
       "9981                   Munchkin Twisty Figure 8 Teether   \n",
       "9982                   Munchkin Twisty Figure 8 Teether   \n",
       "9983                   Munchkin Twisty Figure 8 Teether   \n",
       "9984                   Munchkin Twisty Figure 8 Teether   \n",
       "9985                   Munchkin Twisty Figure 8 Teether   \n",
       "9986                   Munchkin Twisty Figure 8 Teether   \n",
       "9987                   Munchkin Twisty Figure 8 Teether   \n",
       "9988                   Munchkin Twisty Figure 8 Teether   \n",
       "9989                   Munchkin Twisty Figure 8 Teether   \n",
       "9990                   Munchkin Twisty Figure 8 Teether   \n",
       "9991                   Munchkin Twisty Figure 8 Teether   \n",
       "9992                   Munchkin Twisty Figure 8 Teether   \n",
       "9993                   Munchkin Twisty Figure 8 Teether   \n",
       "9994                   Munchkin Twisty Figure 8 Teether   \n",
       "9995                   Munchkin Twisty Figure 8 Teether   \n",
       "9996                   Munchkin Twisty Figure 8 Teether   \n",
       "9997                   Munchkin Twisty Figure 8 Teether   \n",
       "9998                   Munchkin Twisty Figure 8 Teether   \n",
       "9999                   Munchkin Twisty Figure 8 Teether   \n",
       "\n",
       "                                                 review  rating  \n",
       "0     These flannel wipes are OK, but in my opinion ...       3  \n",
       "1     it came early and was not disappointed. i love...       5  \n",
       "2     Very soft and comfortable and warmer than it l...       5  \n",
       "3     This is a product well worth the purchase.  I ...       5  \n",
       "4     All of my kids have cried non-stop when I trie...       5  \n",
       "5     When the Binky Fairy came to our house, we did...       5  \n",
       "6     Lovely book, it's bound tightly so you may not...       4  \n",
       "7     Perfect for new parents. We were able to keep ...       5  \n",
       "8     A friend of mine pinned this product on Pinter...       5  \n",
       "9     This has been an easy way for my nanny to reco...       4  \n",
       "10    I love this journal and our nanny uses it ever...       4  \n",
       "11    This book is perfect!  I'm a first time new mo...       5  \n",
       "12    I originally just gave the nanny a pad of pape...       4  \n",
       "13    I thought keeping a simple handwritten journal...       3  \n",
       "14    Space for monthly photos, info and a lot of us...       5  \n",
       "15    I bought this calender for myself for my secon...       4  \n",
       "16    I love this little calender, you can keep trac...       5  \n",
       "17    This was the only calender I could find for th...       5  \n",
       "18    I completed a calendar for my son's first year...       4  \n",
       "19    We wanted to get something to keep track of ou...       5  \n",
       "20    I had a hard time finding a second year calend...       5  \n",
       "21    I only purchased a second-year calendar for my...       2  \n",
       "22    I LOVE this calendar for recording events of m...       5  \n",
       "23    Calendar is exactly as described, but I find t...       3  \n",
       "24    Wife loves this calender. Comes with a lot of ...       5  \n",
       "25    My daughter had her 1st baby over a year ago. ...       5  \n",
       "26    Extremely useful! As a new mom, tired and inex...       5  \n",
       "27    My son loves peek a boo at this age of 9 month...       3  \n",
       "28    One of baby's first and favorite books, and it...       4  \n",
       "29    I like how the book has a hook to attach it to...       5  \n",
       "...                                                 ...     ...  \n",
       "9970  This is an expensive pillow that is worth buyi...       4  \n",
       "9971  I first heard about this product when research...       4  \n",
       "9972  As for some of the other reviews I can underst...       5  \n",
       "9973  My doctor had told me to do more tummy time wi...       4  \n",
       "9974  This has helped my Now 13 week old son. About ...       5  \n",
       "9975  I'm sure people are buying this product thinki...       2  \n",
       "9976  My son has partial positional plagio, which is...       5  \n",
       "9977  The first day I received this I used it. I not...       5  \n",
       "9978  Because of the bright colors on this items, i ...       2  \n",
       "9979  Overall I think this is a good teether - my ba...       4  \n",
       "9980  A must have for your baby he will love itthe c...       5  \n",
       "9981  Our daughter loves this teether.  She is almos...       5  \n",
       "9982  My son started showing signs of teething aroun...       3  \n",
       "9983  I bought this for my nephew and it keeps him b...       5  \n",
       "9984  My son would NOT use any of the teething toys ...       5  \n",
       "9985  I bought this for my 5 month old great nephew ...       5  \n",
       "9986  This is not only a teether; its a great toy. I...       5  \n",
       "9987  My 4 month old finds this teether's colors ent...       3  \n",
       "9988  she likes it because it's long enough for her ...       4  \n",
       "9989  My 9 month old loves this toy.  It feels good ...       5  \n",
       "9990  Bought this when my baby was about 5 months ol...       5  \n",
       "9991  The shapes this nifty little toy gets into... ...       5  \n",
       "9992  Such a simple easy toy, but my son loves it.  ...       5  \n",
       "9993  my girl didnt like this toy at all, it was not...       2  \n",
       "9994  My daughter played with it only seldomly as an...       3  \n",
       "9995  There no sound or anything and look like there...       1  \n",
       "9996  I purchased this for my 6 month old Grandson a...       5  \n",
       "9997  nice product.  may be too hard for the baby's ...       3  \n",
       "9998  My 5 mo. old son loves this toy! It's great as...       5  \n",
       "9999  Perfect for babies that are teething! very ver...       5  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review\n",
    "\n",
    "Let us explore a specific example of a baby product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      Baby Tracker&reg; - Daily Childcare Journal, S...\n",
       "review    This has been an easy way for my nanny to reco...\n",
       "rating                                                    4\n",
       "Name: 9, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.iloc[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into word-counts.\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation) \n",
    "\n",
    "review_without_puctuation = products['review'].apply(str).apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_split(text):\n",
    "    global my_words\n",
    "    mw = nltk.word_tokenize(text)\n",
    "    for w in mw:\n",
    "        my_words.add(w)\n",
    "        \n",
    "my_words = set()\n",
    "\n",
    "#import nltk\n",
    "# sentence = \"I am a big boy. I'd love to eat ice-cream right now.\"\n",
    "# nltk.word_tokenize\n",
    "# tokens = nltk.word_tokenize(sentence)\n",
    "# print tokens\n",
    "# print type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']\n",
    "        \n",
    "def count_number_of_significant_words(text):\n",
    "    words = text['review'].split()\n",
    "    word_dict = {}\n",
    "    for word in significant_words:\n",
    "        word_dict[word] = 0\n",
    "    for word in words:\n",
    "        if word in significant_words:\n",
    "            if word not in word_dict:\n",
    "                word_dict[word] = 1\n",
    "            else:\n",
    "                word_dict[word] = word_dict[word] + 1\n",
    "    significant_words_counts = []\n",
    "    for word in significant_words:\n",
    "        significant_words_counts.append(word_dict[word]) \n",
    "    return pd.Series(significant_words_counts, index=significant_words)\n",
    "\n",
    "lambdafunc = lambda x: pd.Series(significant_words)\n",
    "\n",
    "newcols = pd.DataFrame(review_without_puctuation).apply(count_number_of_significant_words, axis=1)\n",
    "newcols.columns = significant_words\n",
    "\n",
    "products_with_words = products.join(newcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us explore what the sample example above looks like after these 2 transformations. Here, each entry in the **word_count** column is a dictionary where the key is the word and the value is a count of the number of times the word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_with_words.iloc[9]['love']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9146"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_with_words_ignore_3 = products_with_words[products_with_words['rating'] != 3]\n",
    "len(products_with_words_ignore_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be positive reviews, while the ones with rating of 2 or lower are negative. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiments = products_with_words_ignore_3['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "\n",
    "sentimentsdf = pd.DataFrame(sentiments)\n",
    "sentimentsdf.columns = ['sentiment']\n",
    "\n",
    "products_prepared = products_with_words_ignore_3.join(sentimentsdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the dataset contains an extra column called sentiment which is either positive (+1) or negative (-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set. We use `seed=1` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# X = products_prepared[['rating']]\n",
    "X = products_prepared[significant_words]\n",
    "y = products_prepared['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "\t     y,\n",
    "\t     test_size=0.2,\n",
    "\t     random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. This model will use the column **word_count** as a feature and the column **sentiment** as the target. We will use `validation_set=None` to obtain same results as everyone else.\n",
    "\n",
    "**Note:** This line may take 1-2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "model = logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluate the trained model\n",
    "\n",
    "We will now use the cross-validation set to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
      "          random_state=None, tol=0.0001)\n",
      "{'C': 100000.0, 'intercept_scaling': 1, 'fit_intercept': True, 'penalty': 'l2', 'random_state': None, 'dual': False, 'tol': 0.0001, 'class_weight': None}\n",
      "Prediction sample 1\n",
      "error sum is: 328\n",
      "average_error is: 0.179234972678\n"
     ]
    }
   ],
   "source": [
    "print model\n",
    "print model.get_params()\n",
    "\n",
    "error_sum = 0\n",
    "test_size = len(X_test)\n",
    "\n",
    "print 'Prediction sample', model.predict(X_test[0])[0]\n",
    "\n",
    "for i in range(0, test_size):\n",
    "    error_sum += abs(model.predict(X_test[i])[0] - y_test[i]) / 2\n",
    "\n",
    "print 'error sum is:', error_sum\n",
    "average_error = float(error_sum) / test_size\n",
    "\n",
    "print 'average_error is:', average_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most positive (and negative) review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to examining the full test dataset, **test_data**, and use GraphLab Create to form predictions on all of the test data points for faster performance.\n",
    "\n",
    "Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "1.  Make probability predictions on **test_data** using the `sentiment_model`. (**Hint:** When you call `.predict` to make predictions on the test data, use option `output_type='probability'` to output the probability rather than just the most likely class.)\n",
    "2.  Sort the data according to those predictions and pick the top 20. (**Hint:** You can use the `.topk` method on an SFrame to find the top k rows sorted according to the value of a specified column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifer. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions (**Hint:** Use the `predict` method)\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    # First get the predictions\n",
    "    ## YOUR CODE HERE\n",
    "    ...\n",
    "    \n",
    "    # Compute the number of correctly classified examples\n",
    "    ## YOUR CODE HERE\n",
    "    ...\n",
    "\n",
    "    # Then compute accuracy by dividing num_correct by total number of examples\n",
    "    ## YOUR CODE HERE\n",
    "    ...\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the classification accuracy of the sentiment_model on the test_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_classification_accuracy(sentiment_model, test_data, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz Question: What is the accuracy of the sentiment_model on the test_data? Round your answer to 2 decimal places (e.g. 0.76).\n",
    "Quiz Question: Does a higher accuracy value on the training_data always imply that the classifier is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
